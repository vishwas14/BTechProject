{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BTP_AG.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "iRojDqfuTJjE",
        "A_-8qO7lTSk2"
      ],
      "authorship_tag": "ABX9TyPJNNloRG51naKvByjo0gbE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishwas14/BTechProject/blob/main/BTP_AG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlOwgBsexOl2"
      },
      "source": [
        "# **PART-2**\n",
        "BY- Vishwas Anil Kumar, Arindam Dubey, Naman Sharma"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeoLcpQTPWom"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import random\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.layers import Activation, Dense, LSTM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqwk55cnxFLV"
      },
      "source": [
        "## Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BjwzADSPnIA"
      },
      "source": [
        "#data preprocessing\n",
        "def to_lowercase(text):\n",
        "    return  text.lower()\n",
        "def remove_numbers(text):\n",
        "    result = re.sub(r'\\d+', '', text)\n",
        "    return result\n",
        "def remove_punctuation(text):\n",
        "    text = re.sub(r'[“|”|‘|’]',' ',text)\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    return text.translate(translator)\n",
        "def remove_whitespace(text):\n",
        "    return \" \".join(text.split())\n",
        "def lemmatize_word(text):\n",
        "    word_tokens = word_tokenize(text)\n",
        "    lemmas = [lemmatizer.lemmatize(word, pos='v') for word in word_tokens]\n",
        "    return lemmas\n",
        "\n",
        "file1 = open('T11.txt','r')\n",
        "file2 = open('T22.txt','r')\n",
        "text1 = file1.read()\n",
        "text2= file2.read()\n",
        "\n",
        "\n",
        "text1 = to_lowercase(text1)\n",
        "text1 = remove_numbers(text1)\n",
        "text1 = remove_punctuation(text1)\n",
        "text1 = remove_whitespace(text1)\n",
        "\n",
        "\n",
        "text2 = to_lowercase(text2)\n",
        "text2 = remove_numbers(text2)\n",
        "text2 = remove_punctuation(text2)\n",
        "text2 = remove_whitespace(text2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeD7g-ujQMkS"
      },
      "source": [
        "#text1 = text1[300000:800000]\n",
        "#text2 = text2[300000:800000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRojDqfuTJjE"
      },
      "source": [
        "## T11"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY2UIWFIQ9tE"
      },
      "source": [
        "characters = sorted(set(text1))\n",
        "\n",
        "char_to_index = dict((c, i) for i, c in enumerate(characters))\n",
        "index_to_char = dict((i, c) for i, c in enumerate(characters))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oL7WemHDRBY3"
      },
      "source": [
        "SEQ_LENGTH = 40\n",
        "STEP_SIZE = 3\n",
        "\n",
        "sentences = []\n",
        "next_char = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjpMqY5vRD0x"
      },
      "source": [
        "for i in range(0, len(text1) - SEQ_LENGTH, STEP_SIZE):\n",
        "    sentences.append(text1[i: i + SEQ_LENGTH])\n",
        "    next_char.append(text1[i + SEQ_LENGTH])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Er2uFYr4RHJz"
      },
      "source": [
        "x = np.zeros((len(sentences), SEQ_LENGTH,\n",
        "              len(characters)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences),\n",
        "              len(characters)), dtype=np.bool)\n",
        "\n",
        "for i, satz in enumerate(sentences):\n",
        "    for t, char in enumerate(satz):\n",
        "        x[i, t, char_to_index[char]] = 1\n",
        "    y[i, char_to_index[next_char[i]]] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJgPNCI8RQKX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85r9MmusRTd-"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128,\n",
        "               input_shape=(SEQ_LENGTH,\n",
        "                            len(characters))))\n",
        "model.add(Dense(len(characters)))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LvBs0wKRZt_",
        "outputId": "02cbc340-5542-4925-e3ce-8e45494c03bb"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(lr=0.01))\n",
        "\n",
        "model.fit(x, y, batch_size=256, epochs=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "482/482 [==============================] - 91s 184ms/step - loss: 2.0811\n",
            "Epoch 2/4\n",
            "482/482 [==============================] - 89s 185ms/step - loss: 1.6555\n",
            "Epoch 3/4\n",
            "482/482 [==============================] - 89s 185ms/step - loss: 1.5131\n",
            "Epoch 4/4\n",
            "482/482 [==============================] - 90s 186ms/step - loss: 1.4378\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff236c74d90>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrY2zv1qRcHx"
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23ryTLUzRg7s"
      },
      "source": [
        "def generate_text(length, temperature):\n",
        "    start_index = random.randint(0, len(text1) - SEQ_LENGTH - 1)\n",
        "    generated = ''\n",
        "    sentence = text1[start_index: start_index + SEQ_LENGTH]\n",
        "    generated += sentence\n",
        "    for i in range(length):\n",
        "        x_predictions = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_predictions[0, t, char_to_index[char]] = 1\n",
        "\n",
        "        predictions = model.predict(x_predictions, verbose=0)[0]\n",
        "        next_index = sample(predictions,\n",
        "                                 temperature)\n",
        "        next_character = index_to_char[next_index]\n",
        "\n",
        "        generated += next_character\n",
        "        sentence = sentence[1:] + next_character\n",
        "    return generated"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_yKZq-vRkj0",
        "outputId": "c3f8a841-5bc4-4f6d-f9d6-0ddb5a3c18f6"
      },
      "source": [
        "print(generate_text(300, 0.2))\n",
        "print(generate_text(300, 0.4))\n",
        "print(generate_text(300, 0.5))\n",
        "print(generate_text(300, 0.6))\n",
        "print(generate_text(300, 0.7))\n",
        "print(generate_text(300, 0.8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "d a girl near me say is he her boyfriend i said i said it was a riya said and started the was a speech and all whater and are and realing at the waiter she said i could we will she said whater she said i said in the best be a bricked to starter in the waiter i said i said in the waiter s a college the college in the stall the stall the wa\n",
            "terview of my life three old men sat in a proper i can ish i said in my legs a fine and as a long and said i said with you with a said the month in patna i had started her and and nothing so her are in the the was a college and the contide i wontered to ask and as a coffeet i could have to the the contine i have a that she said i wanted t\n",
            "tire annual budget on the wedding recept at the was roman said i wontered with you are riya should be a contrease i said leave that in almost the planter i said in the will starter hand and will her the way we will be conticule chater a silk which she had have a right hand i had a jam something a belove that s the part of atorth in the ti\n",
            "teachers would tell white men how to say in the sir at my come my mother said i stopped my lang the rich be word is his bat the riches my college ceating on my least the everyone resains whater i wonlering us bihar like silent with a will a ball in like a speech did the my traet whater realic shutumation are of cootels nembed at the count\n",
            "gh of stephen s and trying to be upper college betur you contation hand with riya like on all i said she said in i was to rich something have silent not showed the student at me in long unce the firt too shailes ares we here the you ay one was it whater we didn t work second how to love at him talk she like to family alen talk the out on \n",
            "ad places to buy mattresses and the chear pasing my professed at me alrome as after and of carn who are at me it s bill in persone the was rohan was of ase i was it here you know talk some before a shot my shot alkone my friend the streat are just and all reside firm college i am nlabled be a bill banthmanking i said ging the waiter stay \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_-8qO7lTSk2"
      },
      "source": [
        "## T22"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBFfTLnZR20k"
      },
      "source": [
        "characters = sorted(set(text2))\n",
        "\n",
        "char_to_index = dict((c, i) for i, c in enumerate(characters))\n",
        "index_to_char = dict((i, c) for i, c in enumerate(characters))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H--WR-ONTV2E"
      },
      "source": [
        "SEQ_LENGTH = 40\n",
        "STEP_SIZE = 3\n",
        "\n",
        "sentences = []\n",
        "next_char = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXBhsZ7nTgoz"
      },
      "source": [
        "for i in range(0, len(text2) - SEQ_LENGTH, STEP_SIZE):\n",
        "    sentences.append(text2[i: i + SEQ_LENGTH])\n",
        "    next_char.append(text2[i + SEQ_LENGTH])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yw7tUasLTjqT"
      },
      "source": [
        "x = np.zeros((len(sentences), SEQ_LENGTH,\n",
        "              len(characters)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences),\n",
        "              len(characters)), dtype=np.bool)\n",
        "\n",
        "for i, satz in enumerate(sentences):\n",
        "    for t, char in enumerate(satz):\n",
        "        x[i, t, char_to_index[char]] = 1\n",
        "    y[i, char_to_index[next_char[i]]] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3T-uPfVTm0r"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128,\n",
        "               input_shape=(SEQ_LENGTH,\n",
        "                            len(characters))))\n",
        "model.add(Dense(len(characters)))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaFNjmQQTp10",
        "outputId": "3998f48c-86fc-40df-9a78-45e845a581e8"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(lr=0.01))\n",
        "\n",
        "model.fit(x, y, batch_size=256, epochs=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "48/48 [==============================] - 12s 194ms/step - loss: 2.8715\n",
            "Epoch 2/4\n",
            "48/48 [==============================] - 9s 186ms/step - loss: 2.3936\n",
            "Epoch 3/4\n",
            "48/48 [==============================] - 9s 191ms/step - loss: 2.1133\n",
            "Epoch 4/4\n",
            "48/48 [==============================] - 9s 192ms/step - loss: 1.9264\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff2369b66d0>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPpvfCtFTqZ0"
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnlOUiBnTvEr"
      },
      "source": [
        "def generate_text1(length, temperature):\n",
        "    start_index = random.randint(0, len(text2) - SEQ_LENGTH - 1)\n",
        "    generated = ''\n",
        "    sentence = text2[start_index: start_index + SEQ_LENGTH]\n",
        "    generated += sentence\n",
        "    for i in range(length):\n",
        "        x_predictions = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_predictions[0, t, char_to_index[char]] = 1\n",
        "\n",
        "        predictions = model.predict(x_predictions, verbose=0)[0]\n",
        "        next_index = sample(predictions,\n",
        "                                 temperature)\n",
        "        next_character = index_to_char[next_index]\n",
        "\n",
        "        generated += next_character\n",
        "        sentence = sentence[1:] + next_character\n",
        "    return generated"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkHCwyXVTxhs",
        "outputId": "443644d5-afb0-4b8a-fc2a-5ace62fba2e2"
      },
      "source": [
        "print(generate_text1(300, 0.2))\n",
        "print(generate_text1(300, 0.4))\n",
        "print(generate_text1(300, 0.5))\n",
        "print(generate_text1(300, 0.6))\n",
        "print(generate_text1(300, 0.7))\n",
        "print(generate_text1(300, 0.8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the leeches disappeared the ferns turned the gree the greed the gree the cound the tree reed the treee the gree the stere the core the male the gree the tree the tree stee in thee reed the mare he was fere the sere the tree reed the smere the tree was in the tree rele the greed the sreed the tree res on the tree reed the sreed the s on th\n",
            "task remained she had to crawl along the manhed theee shee the beree the sreed he wass of theee ster up wet steed thee malle the binya lee st en thee rene and the groun the freed the had sing and the ralled on thee rered and the treer luss and she kert on and theee siok the treee benyand the groke the sreed the gree the sleed the treet th\n",
            "angles from the cliff only by doing thise the s on the more the umbrella theee whee the gang wn pree on and there long the reckong the preed in the breyer hers on thee lee st reel of the sared the treed to the wreed the hreed thee she gree we whe mile the groble of to he cafed tuer of the tree sed ende the merer chee and the sere the bree\n",
            " prior permission of the publisher any upreed the becer to water he wheg in the carige the umbrella the sreed her deee steor the rreedr the serering the the breed strele the or bonyo her whe breed and thee chee tang to wore the the gore thee s you theing the juccris benya loun stee bring to in the tras un he sreet the frond theng thee ran\n",
            "er bare legs they fell off by themselves bet ined on the treeer the breer the bregey on theted and the gackere and tvener wheee and wereed forlen for list out and thees stee the ware and wong to phe spered he binya upee ivered freclred for anderto rers and the urbrella up ut of the here to hels un atreed theee whe hes des fred binya kye b\n",
            "in his grasp at last he had only to hide remarerthing sithod thelaruge to the rreey rerom ver qiwcond the croed tur banya stong rejjweded of in thee layid  up ofer it it romee tee ging the tow on theee rout besply wood the sladei st to pared saede the ples ras dheas on bethe thete gest and boteod the rere shed of tame and wnter theiy in o\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzd5JYMNciQh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}